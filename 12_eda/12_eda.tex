\documentclass[12pt,t]{beamer}
\usepackage{graphicx}
\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}

\input{../LaTeX/header.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end of header
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Tools for Reproducible Research}
\subtitle{Organizing projects; exploratory data analysis}
\author{\href{http://kbroman.org}{Karl Broman}}
\institute{Biostatistics \& Medical Informatics, UW{\textendash}Madison}
\date{\href{http://kbroman.org}{\tt \scriptsize \color{foreground} kbroman.org}
\\[-4pt]
\href{https://github.com/kbroman}{\tt \scriptsize \color{foreground} github.com/kbroman}
\\[-4pt]
\href{https://twitter.com/kwbroman}{\tt \scriptsize \color{foreground} @kwbroman}
\\[-4pt]
{\scriptsize Course web: \href{http://kbroman.org/Tools4RR}{\tt kbroman.org/Tools4RR}}
}

\begin{document}

{
\setbeamertemplate{footline}{} % no page number here
\frame{
  \titlepage

\note{I'm trying to cover two things here: how to organize data
  analysis projects, so in the end the results will be reproducible
  and clear, and how to capture the results of exploratory data
  analysis.

  The hardest part, regarding organizing projects, concerns how to coordinate
  collaborative projects: to keep data, code, and results synchronized
  among collaborators.

  Regarding exploratory data analysis, we want to capture the whole
  process: what you're trying to do, what you're thinking about, what
  you're seeing, and what you're concluding and why. And we want to do
  so without getting in the way of the creative process.

  I'll sketch what I try to do, and the difficulties I've had. But I
  don't have all of the answers.
}
} }


\begin{frame}[c]{}

\begin{center}
\large
File organization and naming \\
are powerful weapons against chaos.

\end{center}
\hfill
{\lolit
{\textendash} \href{http://www.stat.ubc.ca/~jenny/}{Jenny Bryan}
}

\note{You don't {\nhilit need} to be organized, but it sure will help
  others (or yourself, later), when you try to figure out what it was
  that you did.

  Segregate all the materials for a project in one directory/folder on
  your harddrive.

  I prefer to separate raw data from processed data, and I put code in
  a separate directory.

  Write {\tt ReadMe} files to explain what's what.
}
\end{frame}


\begin{frame}[fragile]{Organizing your stuff}

\vspace{6pt}

\begin{lstlisting}
Code/d3examples/
    /Others/
    /PyBroman/
    /Rbroman/
    /Rqtl/
    /Rqtlcharts/
Docs/Talks/
    /Meetings/
    /Others/
    /Papers/
    /Resume/
    /Reviews/
    /Travel/
Play/
Projects/AlanAttie/
        /BruceTempel/
        /Hassold_QTL/
        /Hassold_Age/
        /Payseur_Gough/
        /PhyloQTL/
        /Tar/
\end{lstlisting}

\note{This is basically how I organize my hard drive. You want it to be
  clear where things are. You shouldn't be searching for stuff.

  In my {\tt Projects/} directory, I have a {\tt Tar/} directory with
  {\tt tar.gz} files
  of older projects; the same is true for other directories, like
  {\tt Docs/Papers/} and {\tt Docs/Talks/}.
}
\end{frame}


\begin{frame}[fragile]{Organizing your projects}

\vspace{6pt}

\begin{lstlisting}
Projects/Hassold_QTL/

    Data/
    Notes/
    R/
    R/Figs/
    R/Cache/
    Rawdata/
    Refs/

    Makefile
    Readme.txt

    Python/convertGeno.py
    Python/convertPheno.py
    Python/combineData.py

    R/prepData.R
    R/analysis.R
    R/diagnostics.Rmd
    R/qtl_analysis.Rmd
\end{lstlisting}

\note{This is how I'd organize a simple project.

  Separate the raw data from processed data.

  Separate code from data.

  Include a Readme file and a Makefile.

  I tend to reuse file names. Almost every project will have an {\tt
    R/prepData.R} script.

  Of course, each project is under version control (with git)!

  {\tt R/analysis.R} usually has exploratory analyses, and then
  there'll be separate {\tt .Rmd} files with more finalized work.
}
\end{frame}


\begin{frame}[fragile]{Organizing a paper}

\vspace{6pt}

\begin{lstlisting}
Docs/Papers/PhyloQTL/

    Analysis/
    Data/
    Figs/
    Notes/
    R/
    SuppFigs/

    ReadMe.txt
    Makefile
    phyloqtl.tex
    phyloqtl.bib

    Submitted/
    Reviews/
    Revised/
    Final/
    Proofs/
\end{lstlisting}

\note{This is how I organize the material for a paper.

  {\tt R/} contains code for figures; {\tt Analysis/} contains other
  analysis code; {\tt Data/} contains data; {\tt Figs/} contains the
  figures; {\tt Notes/} contains notes or references.

  Of course, a {\tt Makefile} for compiling the PDF, and perhaps a
  {\tt ReadMe} file to explain where things are.

  And I'll save the submitted version (and text files with bits
  for web forms at submission), plus reviews, the revised version plus
  response to reviews, and then the final submitted version and the
  proofs.
}
\end{frame}


\begin{frame}[fragile]{Organizing a talk}

\vspace{6pt}

\begin{lstlisting}
Docs/Talks/SampleMixups/

    Figs/
    R/

    ReadMe.txt
    Makefile
    bmi2013.tex

    Old/
\end{lstlisting}

\note{This is how I organize the material for a talk: much like a
  paper, but generally a bit simpler.

  Again, {\tt R/} contains code for figures and {\tt Figs/} contains
  the actual figures.

  And again, a {\tt Makefile} for compiling the PDF, and perhaps a
  {\tt ReadMe} file to explain where things are.

  And I'll save all old versions in {\tt Old/}
}
\end{frame}




\begin{frame}{Basic principles}

\vspace{18pt}

\bi
\item Develop your own system
\item Put everything in a common directory
\item Be consistent
\bi
\item directory structure; names
\ei
\item Separate raw from processed data
\item Separate code from data
\item It should be obvious what code created what files, and what the
  dependencies are.
\item No hand-editing of data files
\item Don't use spaces in file names
\item Use relative paths, not absolute paths
\bi
\item[] {\tt \hilit ../blah} \; not \; {\tt \vhilit {\textasciitilde}/blah} \; or \; {\tt \vhilit /users/blah}
\ei
\ei

\note{I work on many different projects at the same time, and I'll
  come back to a project 6 months or a year later.

  I don't want to spend much time figuring out where things are
  and how things were created: have a {\tt Makefile}, and keep notes. But
  notes are not necessarily correct while a {\tt Makefile} would be.

  Plan for the whole deal to ultimately be open to others: will you be
  proud of the work, or embarrassed by the mess?
}
\end{frame}


\begin{frame}[c]{}

\centering
\large
Your closest collaborator is you six months ago, but you
don't reply to emails.
\note{I heard this from Paul Wilson, UW-Madison.

  The original source is a tweet by Karen Cranston, quoting Mark
  Holder.

  {\tt https://twitter.com/kcranstn/status/370914072511791104}
}
\end{frame}



\begin{frame}[c]{}

\centering
\large
Organization takes time.

\note{There's no getting around the fact that doing things properly
  takes longer, in the short term.

  If you have a good system and good habits, it won't seem like it
  takes so long.

  But definitely, it's a large up-front investment in
  order to potentially save a lot of time and aggravation later.
}
\end{frame}



\begin{frame}{Painful bits}

\vspace{24pt}

\bi
\item Coming up with good names for things
\bi
\item Code as verbs; data as nouns
\ei
\item Stages of data cleaning
\item Going back and redoing stuff
\item Clutter of old stuff that you no longer need
\item Keeping track of the order of things
\bi
\item dependencies; what gave rise to what
\ei
\item Long, messy Makefiles
\ei

\vspace{18pt}

\only<2|handout>{\centerline{\hilit $\rightarrow$ Modularity}}

\note{I don't have many solutions to these problems. Version control
  helps. And try to break things down into different stages, in
  case one aspect needs to be revised. Maybe use different
  subdirectories for the different stages of data cleaning.

  A point that was raised in the discussion: Have periodic
  ``versions'' for a project, perhaps labeled by date. Move all the
  good stuff over and retire the stuff that is no longer useful or necessary.
}
\end{frame}


\begin{frame}[c]{}

\vspace{24pt}

\figh{Figs/iso_8601.png}{0.8}

\vfill

\hfill {\tt \footnotesize \lolit \href{http://xkcd.com/1179/}{xkcd.com/1179}}

\note{Go with the xkcd format for writing dates, for ease of sorting.
}
\end{frame}



\begin{frame}{Problem: Variations across data files}

\vspace{24pt}

\bi
\item Different files (or parts of files!) may have different formats.
\item Variables (or factor levels) may have different names in
  different files.
\item The names of files may inconsistent.
\ei

\bigskip

\bi
\item It's tempting to hand-edit the files. {\vhilit Don't!}
\item Create another meta-data file that explains what's what.
\ei

\note{Scientists aren't trained in how to organize data.

  Multiple people in a lab might have his/her own system, or an
  individual's system may change over time (or from the top to the
  bottom of a file!)

  Create a separate file with meta-data: ``These are the files. In
  this file, the variable is called {\nhilit blah} while in that file it's
  {\nhilit blather}.''

  The meta-data file should be structured as data (e.g., as a comma-
  or tab-delimited file) for easy parsing.
}
\end{frame}



\begin{frame}{Tidy data}

\vspace{24pt}

Read Hadley Wickham's
\href{http://vita.had.co.nz/papers/tidy-data.pdf}{paper on Tidy Data}.

\vspace{12pt}

\bi
\item Each variable forms a column.
\item Each observation forms a row.
\item Each type of observational unit forms a table.
\ei

\vspace{12pt}

{\footnotesize
\renewcommand{\arraystretch}{1.05}
\begin{center}
\begin{tabular}{ccc} \hline
Mouse & Treatment & Response \\ \hline
 1    & control  & -- \\
 1    &   ttt    & 7.4 \\
 2    & control  & 3.8 \\
 2    &   ttt    & 5.2 \\
 3    & control  & 5.5 \\
 3    &   ttt    & 6.6 \\ \hline
\end{tabular}
\end{center}
}

\note{Read the paper!

  When you convert data into a better form, convert it into the {\nhilit
  tidy} form.

  Also, consider Hadley's tools, like dplyr
}
\end{frame}






\begin{frame}[fragile]{Problem: 80 million side projects}

\vspace{24pt}

\begin{lstlisting}
$ ls ~/Projects/Attie

AimeeNullSims/        Deuterium/             Ping/
AimeeResults/         ExtractData4Gary/      Ping2/
AnnotationFiles/      ForFirstPaper/         Ping3/
Brian/                FromAimee/             Ping4/
Chr10adipose/         GoldStandard/          Play/
Chr6_extrageno/       HumanGWAS/             Proteomics/
Chr6hotspot/          Insulin/               R/
ChrisPlaisier/        Islet_2011-05/         RBM_PlasmaUrine/
Code4Aimee/           Lusis/                 R_adipose/
CompAnnot/            MappingProbes/         R_islet/
CondScans/            Microarrays/           Rawdata/
D2O_2012-02-14/       MultiProbes/           Scans/
D2O_Nrm_2012-02-29/   NewMap/                SimsRePower/
D2O_cellcycle/        Notes/                 Slco1a6/
D2Ocorr/              NullSims/              StudyLineupMethods/
Data4Aimee/           NullSims_2009-09-10/   eQTLPaper/
Data4Tram/            PepIns_2012-02-09/     transeQTL4Lude/
\end{lstlisting}
\note{This is a project-gone-wrong.

  A key problem in research is that you don't really know what you're
  doing when you get started. It seems best to separate out each
  side-project as a separate directory, but it can be a nightmare to
  find things later.

  If each of these subdirectories was nicely organized and had a
  {\tt ReadMe} file, you could {\tt grep} your way through them.

  I sort of like the idea of separate directories for the different
  aspects of mucking about. And second versions are always better. Maybe
  we should plan to muck about separately and then bring a more
  refined analysis back into a common directory?

  A point raised in the discussion:   Put defunct side projects into
  an {\tt Old/} subdirectory, and put active but not yet clearly
  interesting ones into {\tt New/} or {\tt Play/}. This will help to
  avoid the clutter.
}
\end{frame}



\begin{frame}{Saving intermediate results}

\vspace{24pt}

{\hilit R Markdown document with details of data cleaning.}

\bi
\item Within the {\tt .Rmd} file, periodically {\tt save} the state of
  things, for further exploratory analysis.

\item Put those intermediate files (which might be large) in a common
  subdirectory.

\item The subdirectory could be under {\hilit separate} version
  control.

\item But you'll need to {\hilit go in there} and commit files.
\ei


\note{I want a reproducible analysis document, but I want to be able
  to grab objects from the middle of the process for further
  exploration. So I'll include code chunks to save the state of
  things, say in a {\tt Cache} or {\tt RData} subdirectory.

  Subdirectories can be their own git repositories:
  Include that subdirectory in the {\tt .gitignore} file, and then
  use {\tt git init} within the subdirectory.

  A point raised in the discussion: how to synchronize a project
  between computers? If we don't put the intermediate files in the
  main repository, we can't rely on GitHub. (For a simple manuscript
  or talk, it's okay to reconstruct things on another computer, but
  for big analyses, you wouldn't want to.) I use ChronoSync to
  synchronize my Mac desktop and laptop. Maybe Dropbox or Google Drive
  would be useful for this. You'd still want to use git and
  and GitHub, but you could supplement them by having the repository
  sit in your Dropbox folder.
}
\end{frame}




\begin{frame}{Problem: Coordinating with collaborators}

\vspace{24pt}

\bi
\item Where to put data that multiple people will work with?
\item Where to put intermediate/processed data?
\item Where to indicate the code that created those processed data files?
\item How to divvy up tasks and know who did what?
\ei

\vspace{12pt}

\bi
\item Need to agree on directory structure and file naming conventions
\item Consider symbolic links for shared data directories
\bi
\item[] {\tt ln -s /z/Proj/blah}
\item[] {\tt ln -s /z/Proj/blah my\_blah}
\ei
\ei

\note{Ideally, everything synchronized with git/GitHub.

  The keys: planning and regular communication

  Symbolic links are also called ``soft links.'' It's just like a file
  shortcut in Windows.
}
\end{frame}






\begin{frame}{Problem: Collaborators who don't use git}

\vspace{24pt}

\only<2|handout 0>{

\vspace*{48pt}

\centerline{Um\dots}
}

\only<3|handout>{
\bi
\item Use git yourself
\item Copy files to/from some shared space
  \bi
  \item Ideally, in an automated way
  \ei
\item Commit {\hilit their} changes.
\ei
}

\note{Life would be easier if all of our analysis collaborators
  adopted git. Teach them how?!

  When I'm working with a collaborator on a paper, I may get comments
  from them as a marked-up PDF. I'll save that in the repository and
  will incorporate and commit the changes in the source files, on my
  own.
}
\end{frame}




\begin{frame}{Exploratory data analysis}

\vspace{24pt}

\bi
\item what were you trying to do?
\item what you're thinking about?
\item what did you observe?
\item what did you conclude, and why?
\ei

\note{We want to be able to capture the full outcome of exploratory
  data analysis.

  But we don't want to inhibit the creative flow. How to capture this
  stuff?
}
\end{frame}


\begin{frame}{Avoid}

\vspace{24pt}

\bi
\item "How did I create this plot?"
\item "Why did I decide to omit those six samples?"
\item "Where (on the web) did I find these data?"
\item "What was that interesting gene?"
\ei

\note{I've said all of these things to myself.
}
\end{frame}



\begin{frame}{Basic principles}

\vspace{24pt}

\bi
\item[] {\hilit Step 1}: slow down and document.
\item[] {\hilit Step 2}: have sympathy for your future self.
\item[] {\hilit Step 3}: have a system.
\ei

\note{I can't emphasize these things enough.

  If you're not {\nhilit thinking} about keeping track of things, you
  won't keep track of things.

  One thing I like to do: write a set of comments describing my basic
  plan, and then fill in the code afterwards. It forces you to think
  things through, and then you'll have at least a rough sense of what
  you were doing, even if you don't take the time to write further
  comments.
}
\end{frame}

\begin{frame}{Capturing EDA}

\vspace{24pt}

\bi
\item copy-and-paste from an R file
\item grab code from the {\tt .Rhistory} file
\item Write an informal R Markdown file
\item Write code for use with the KnitR function {\tt spin()}
\bi
\item[] Comments like \; {\hilit \tt \#' This will become text}
\item[] Chunk options like so: \; {\hilit \tt \#+ chunk\_label, echo=FALSE}
\ei
\ei

\note{There are a number of techniques you can use to capture the EDA
  process.

  You don't need to save all of the figures, but you do need to save
  the code and write down your motivation, observations, and
  conclusions.

  I usually start out with a plain R file and then move to more formal
  R Markdown or AsciiDoc reports.
}
\end{frame}


\begin{frame}[fragile]{A file to {\tt spin()}}

\vspace{24pt}

\begin{lstlisting}
#' This is a simple example of an R file for use with spin().

#' We'll start by setting the seed for the RNG.
set.seed(53079239)

#' We'll first simulate some data with x ~ N(mu=10, sig=5) and
#' y = 2x + e, where e ~ N(mu=0, sig=2)
x <- rnorm(100, 10, 5)
y <- 2*x + rnorm(100, 0, 2)

#' Here's a scatterplot of the data.
plot(x, y, pch=21, bg="slateblue", las=1)
\end{lstlisting}

\note{Here's an example R file for use with {\tt spin()}.
}
\end{frame}




\begin{frame}{I almost forgot}

\vspace{64pt}

\centerline{\Large Backups}

\only<2|handout>{
  \vspace{48pt}

  \centerline{Next two weeks: {\hilit Clear code} and {\hilit R packages}}
}

\note{You {\nhilit must} back up your stuff.

      You can generally rely on your department server, and you should
      also make use of GitHub. But if you have other stuff on a laptop
      or at home, you want to be sure to back that up to. Hard drives
      are cheap.

      On a Mac, I use the built-in Time Machine, but I also use
      SuperDuper! to create a bootable clone.

      Also important in all of this is writing clear, modular
      code. With R, it's best to pull out reuseable code as an R
      package. We'll talk about these two topics over the next two
      weeks.
}
\end{frame}


\end{document}
