## Lessons

- Follow up artifacts; they might be the most interesting results

- The simplest things can be the most important

- Consider taking logs, especially for ratios or when values span
  several orders of magnitude.

- Including data summaries in an analysis report can help to catch
  errors

- File organization, documentation, version control: investments that
  pay off in the long term

- Computer simulations have a lot of great uses

- The EM algorithm is really useful; use the log likelihood as a diagnostic

- Don't just cram your data into the standard approach

- Cramming your data into the standard approach might work fine

- if it seems too good to be true, it probably is

- always ask: does this make sense?

- omitting data is usually bad; crudely ignoring correlations is often
  perfectly fine

- extracting the _full_ information from the data may not be worth
  the effort

- time to solve a computational problem includes the time to formulate a solution,
  to write the program, to run the program, and to make sense of the
  results. Program run time is almost always the least of these.

- use computer simulations to check that your software/method is
  giving reasonable results


## Principles

- Start with an understanding of the problems and data

- Think about a model for the data-generating process

- Modify your desires to match the defaults; focus your compulsive
  behavior on things that matter.


## Further lessons

- the most important thing is that you get the right answer

- if you find a bug, first create a test that reproduces it, then fix it

- capture the full process of data cleaning (what you did, what you
  saw, how you interpreted it, why you made the decisions you made),
  because you'll want that information later
