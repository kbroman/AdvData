\documentclass[aspectratio=169,12pt,t]{beamer}
\usepackage{graphicx}
\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}

\input{../LaTeX/header.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end of header
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Wrangling messy data files}
\author{\href{https://kbroman.org}{Karl Broman}}
\institute{Biostatistics \& Medical Informatics, UW{\textendash}Madison}
\date{\href{https://kbroman.org}{\tt \scriptsize \color{foreground} kbroman.org}
\\[-4pt]
\href{https://github.com/kbroman}{\tt \scriptsize \color{foreground} github.com/kbroman}
\\[-4pt]
\href{https://twitter.com/kwbroman}{\tt \scriptsize \color{foreground} @kwbroman}
\\[-4pt]
{\scriptsize Course web: \href{https://kbroman.org/AdvData}{\tt kbroman.org/AdvData}}
}

\begin{document}

{
\setbeamertemplate{footline}{} % no page number here
\frame{
  \titlepage

\note{
  In this lecture, we'll look at the problem of wrangling messy data
  files: A bit of data diagnostics, but mostly how to reorganize data
  files.
}
} }


\begin{frame}[c]{}

\centering
\Large

{
\color{title}

``In what form would you like the data?''
}

\bigskip \bigskip

\onslide<2->{
{\hilit

    ``In its present form!''
}
}

\bigskip \bigskip \bigskip \bigskip
\onslide<3>{
\lolit
\large
\qquad \qquad \qquad   ...so we'll have some messy files to deal with.
}

\note{
  When collaborators ask me how I would like them to send me data, I
  always say: in its present form.

  I cannot emphasize enough: If any transformation needs to be
  done, or if anything needs to be fixed, it is the data scientist who
  is in the best position to do the work, reproducibly and without
  introducing further errors.

  But that means I spend a lot of time mucking about with some pretty
  messy files.  In the lecture today, I want to impart some tips on
  things I've learned, doing so.
}

\end{frame}


\begin{frame}{Challenges}

  \bigskip

  {\large \vhilit Consistency}

  \bigskip

  \bi
\item file names
\item file organization
\item subject IDs
\item variable names
\item categorical data
  \ei

    \note{
      Essentially all of the challenges come from inconsistencies: in
      file names, the arrangement of data within files, the subject
      identifiers, the variable names, and the categories in
      categorical data.

      Code re-organizing data is the worst code.
    }

\end{frame}





\begin{frame}{Inconsistent IDs}

  \includegraphics[width=0.8\textwidth]{Figs/attiedo_wave2_sheet1.png}

  \only<2>{
    \vspace{-0.6\textheight}
    \hspace{0.1\textwidth}
    \includegraphics[width=0.8\textwidth]{Figs/attiedo_wave5_sheet1.png}
  }

\note{
  The format of the IDs is different between these files. Also in one
  of the files, there are missing dates that will need to be grabbed
  from some separate file.
}
\end{frame}





\begin{frame}[c]{Inconsistent layout}

  \begin{columns}
    \column{0.5\textwidth}

    \figw{Figs/attiedo_wave2_gtt.png}{1.0}

    \column{0.5\textwidth}

    \figh{Figs/attiedo_wave3_gtt.png}{0.8}
  \end{columns}


\note{
  Another example of inconsistent layout. And messy, in both cases.
  You need to fill in the repeated values like mouse ID, and the
  column names are missing in the file on the right.
}
\end{frame}


\begin{frame}{All kinds of inconsistencies}

  \includegraphics[height=0.6\textheight]{Figs/attiedo_wave2_sacwts.png}

  \only<2->{
    \vspace{-0.5\textheight}
    \hspace{0.1\textwidth}
  \includegraphics[height=0.6\textheight]{Figs/attiedo_wave3_sacwts.png}
  }

  \only<3->{
    \vspace{-0.5\textheight}
    \hspace{0.2\textwidth}
  \includegraphics[height=0.6\textheight]{Figs/attiedo_wave4_sacwts.png}
  }

  \only<4>{
    \vspace{-0.5\textheight}
    \hspace{0.3\textwidth}
  \includegraphics[height=0.6\textheight]{Figs/attiedo_wave5_sacwts.png}
  }

\note{
  The layouts, IDs, and included information are all inconsistent here.
}
\end{frame}




\begin{frame}[c]{Multiple rectangles}

\figw{Figs/attiedo_multicolumn.png}{1.0}

\note{
  Here's an example where they have a group of columns with one set of
  data, a few blank columns, then a group of columns with another set
  of data.
}

\end{frame}







\begin{frame}{Stuff moving around}

  \includegraphics[width=0.8\textwidth]{Figs/attiedo_do118_exvivo.png}

  \only<2>{
    \vspace{-0.6\textheight}
    \hspace{0.1\textwidth}
    \includegraphics[width=0.8\textwidth]{Figs/attiedo_do121_exvivo.png}
  }


  \note{
    This has a super-complicated layout, has 500 worksheets with one
    mouse each, and the order of things aren't entirely consistent.
  }
\end{frame}



\begin{frame}{Being self-sufficient}

  \bbi
\item {\hilit C}
\item {\hilit P}erl (or python or ruby\only<2>{ or R})
\item {\hilit R}
  \ei

    \note{
      I've long said that for a data scientist to be self-sufficient,
      they should be savvy with multiple programming languages.

      R for data analysis. C for when you need high-performance, and
      for like 15 years I used Perl for manipulating data files plus
      shell scripting.

      But I'd now say use Python or Ruby instead of Perl; probably
      Python. And really, I think we can now do everything we want to
      do in R. It's a perfectly sufficient general programming language.
    }

\end{frame}




\begin{frame}{Key techniques}

  \bbi
\item stepping through a file
\item regular expressions
  \bi
  \item search and replace patterns
  \ei
\item parsing individual lines in a file
\item matching vectors
\item construct meta data
\item system calls
  \ei

    \note{
    }

\end{frame}








\begin{frame}{Stepping through a file in R}

\note{
  {\tt readLines()}

  slurping it all in vs
  opening/closing a file for reading.

file() and readLines() to read bits at a time.
con <- file("blah.txt", open="r")
readLines(con, n=5)
readLines(con, n=5)
close(con)


  If it's really big, if there's a header to parse first, if we just want a small part of it.
}
\end{frame}







\begin{frame}{Regular expressions}

\note{
  In R, {\tt grep}, {\tt grepl}, {\tt sub}, {\tt gsub}.
  Can use {\tt \\1}, {\tt \\2} in the substitutions.
}
\end{frame}







\begin{frame}{Parsing strings}

\note{
  A lot of {\tt strsplit()} and then messing about with lists.

  Consider {\tt stringr} package.
}
\end{frame}






\begin{frame}{Matching vectors}

\note{
  Mostly {\tt match()}. Need to check for missing values in the result.

  Often use this to reorder the rows or columns in one data set to
  match the rows or columns in another data set.
}
\end{frame}






\begin{frame}[c]{Construct meta data}


\figh{Figs/attiedo_metadata_example.png}{0.9}


\note{
  This is an example meta data file that I set up because each batch
  of subjects in a project had the data organized completely
  differently.

  I identified the variables of interest and chose a fixed set of
  names.

  Then for each batch, I worked out which file it was in, the name of
  the column to look for, and then I also needed a column ``offset''
  because to find week 4 measurements for variable X, you might look
  for the column that is two to the right from the one labeled Y.
}
\end{frame}





\begin{frame}{R challenges}

  \bbi
\item {\tt stringsAsFactors}
\item {\tt check.names} in {\tt read.csv()}
\item dealing with factors
  \bi
\item levels
\item converting to/from strings
  \ei
  \ei

\note{
 Mention the forcats package.
}
\end{frame}


\begin{frame}{Further tips}

\bbi
\item Avoid using numeric indices
  \bi
\item refer to data by variable name and individual ID
\item this will be more {\hilit robust}
  \ei
\item {\tt glue} package vs {\tt paste}, {\tt paste0}
\item {\tt stopifnot()} to assert things that should be true
\item {\tt cbind} and {\tt rbind}, but padding with missing values
\item Sometimes converting excel -> csv loses precision
  \ei

  \note{
  }
\end{frame}




\begin{frame}{Verify everything}

\bbi
\item subject IDs unique?
\item derived columns
\item (other stuff from eda lecture)
\ei

  \note{
  }
\end{frame}




\begin{frame}{Reproducible reports}

\bbi
\item You want all of this work to be reproducible
\item Consider combining the data reorganization with the data
  cleaning
  \bi
    \item a lot of double-checking is happening when reorganizing
  \ei
\item Or clean each file one at a time
  \bi
    \item do the detailed diagnostics and cross-checks with data that are
      in a more convenient form
  \ei
\item Include diagnostic plots
  \bi
    \item Plot stuff vs time
    \item Scatterplots of different variables
    \item Look at missing data pattern
  \ei
\item Explain your thought process and observations
  \ei

  \note{
  }
\end{frame}








\end{document}
