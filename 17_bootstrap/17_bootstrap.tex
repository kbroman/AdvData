\documentclass[aspectratio=169,12pt,t]{beamer}
\usepackage{graphicx}
\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}

\input{../LaTeX/header.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end of header
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{The bootstrap}
\subtitle{Confidence intervals for QTL location}
\author{\href{https://kbroman.org}{Karl Broman}}
\institute{Biostatistics \& Medical Informatics, UW{\textendash}Madison}
\date{\href{https://kbroman.org}{\tt \scriptsize \color{foreground} kbroman.org}
\\[-4pt]
\href{https://github.com/kbroman}{\tt \scriptsize \color{foreground} github.com/kbroman}
\\[-4pt]
\href{https://twitter.com/kwbroman}{\tt \scriptsize \color{foreground} @kwbroman}
\\[-4pt]
{\scriptsize Course web: \href{https://kbroman.org/AdvData}{\tt kbroman.org/AdvData}}
}

\begin{document}

{
\setbeamertemplate{footline}{} % no page number here
\frame{
  \titlepage

\note{
  In this lecture, we'll look at the bootstrap; a method to get
  standard errors and confidence intervals by resampling one's own
  data. But then we'll proceed to an example where the bootstrap
  performs terribly.
}
} }


\begin{frame}[c]{}

  \figh{Figs/bootstrap_cover.jpg}{0.9}

\note{
  The bootstrap is crazy useful. Brad Efron has a big book about it, but
  I'd start with this shorter one with Rob Tibshirani.

  As I've emphasized before, computer simulation is really useful. The
  bootstrap can be seen as an extension of that point.
}

\end{frame}



\begin{frame}[c]{Example}

\only<1|handout 0>{\figw{Figs/bootstrap_illu_1.pdf}{1.0}}
\only<2>{\figw{Figs/bootstrap_illu_2.pdf}{1.0}}

\note{
  Consider the case that you are seeking to estimate the 95th
  percentile of some population.

  You have data on a random sample with $n$=1000. What can you say
  about the standard error of the sample estimate? How could we figure
  this out?

  Well, if we {\hilit knew} the population distribution, we could
  simulate from it. Simulate a sample of size $n$=1000, calculate the
  95th percentile, and then repeat that a bunch of times. The
  distribution of the estimates is what we're interested it; the SD is
  the standard error we're looking for.
}
\end{frame}



\begin{frame}[c]{Parametric bootstrap}

\only<1|handout 0>{\figw{Figs/bootstrap_illu_3.pdf}{1.0}}
\only<2>{\figw{Figs/bootstrap_illu_4.pdf}{1.0}}

\note{
  But of course we don't know the population distribution. But we
  might have a model for it (for example, that it follows a scaled
  chi-square distribution). We could use our data to estimate the
  population distribution.

  We could then simulate from the estimated population distribution,
  and determine the distribution (and so the SE) of our estimate in
  the case that the population follows that estimated distribution.

  This is called the {\hilit parametric bootstrap}: you have a model
  for the underlying population, you use your data to estimate that
  model, and then you simulate from the model in order to get an
  understanding of your target estimator.
}
\end{frame}





\begin{frame}[c]{Non-parametric bootstrap}

\only<1|handout 0>{\figw{Figs/bootstrap_illu_5.pdf}{1.0}}
\only<2>{\figw{Figs/bootstrap_illu_6.pdf}{1.0}}

\note{
  But if we have enough data, we could use the data itself (the
  {\hilit empirical distribution}) as an estimate of the population
  distribution. We could then simulate from {\vhilit that}.

  In other words, we make draws {\hilit with replacement} from our
  observed data, to create a new sample of the same size. We calculate
  our estimate with this re-sampled data, and then repeat many times,
  to get an estimate of the distribution of the estimator.

  This is called the {\hilit non-parametric bootstrap}: skip modeling
  the underlying population and just use your data to approximate the
  population, then simulate (re-sample) from that empirical
  distribution in order to get an understanding of your target
  estimator.
}
\end{frame}







\begin{frame}[c]{}

  \centering
  \Large
  \color{title}

  Don't think ``{\hilit re-sampling}''

  \bigskip \bigskip

  Think ``{\hilit simulate from an estimate of the population}''

\note{
  Folks often focus on the re-sampling aspect of the bootstrap. But I
  think it's better to focus on estimating the population distribution
  and then simulating from that estimate.

  The key idea in the bootstrap is not resampling, but estimating the
  population distribution with the empirical distribution.
}
\end{frame}





\begin{frame}[c]{}

  \centering
  \Large

  How can we tell if the bootstrap works?

  \bigskip \bigskip

  \onslide<2>{\vhilit Simulate!}


\note{
  The bootstrap works well in lots of cases. It's dependent on having
  a reasonably large dataset. And its performance depends on the
  nature of the estimate.

  How can we tell if it works? Well, we could simulate. Basically, we
  could create a {\hilit nested bootstrap}.
}
\end{frame}






\begin{frame}[c]{Nested bootstrap}

\only<1|handout 0>{\figw{Figs/nested_bootstrap_1.pdf}{1.0}}
\only<2>{\figw{Figs/nested_bootstrap_2.pdf}{1.0}}


\note{
  The idea is to treat your data as the true population distribution.
  Sample from it and you have some data.

  Then take that data and apply the bootstrap method to it: treat it
  as the population distribution (or fit a model to get an estimated
  population distribution) and then simulate from it, calculate your
  estimate, and repeat many times. So that gives you one
  bootstrap-based SE.

  You then go back and get a new sample of data from your observed
  data, and then apply the bootstrap again, and then repeat many
  times.
}
\end{frame}






\begin{frame}[c]{Nested bootstrap results}

\figh{Figs/nested_bootstrap_3.pdf}{0.9}


\note{
   The result of this is you have a bunch of estimates of your
   parameter, for different samples from your data, plus you have a
   bootstrap-based SE for each.

   On the top panel here, I show the estimated quantiles from 1000
   samples from my data. The odd multimodal features are due to the
   discrete nature of my original data. The SD of these estimates is
   2.14. That's sort of the ``real'' standard error of my estimate.

   In the lower panel, I show the estimated SE (by the bootstrap) from
   each of 1000 samples from my original data. The average SE is 2.01,
   which is a bit smaller than the SD of the top histogram.

   So the bootstrap is slightly under-estimating the SE, and it's not
   particularly well estimated (with an SD of like 0.5). But we can
   see that it is not {\hilit too} badly behaved.

   Note that you could do all of this, looking at confidence
   intervals. And you might measure something like their coverage, and
   maybe also their width.
}
\end{frame}








\begin{frame}{}

\figh{Figs/visscher1996.png}{0.9}

\note{
   When you have mapped a QTL (a genetic locus that affects a
   quantitative trait), it is important to establish a confidence
   interval for the location of the QTL. This can guide further
   experiments: how precisely have you mapped the locus, and are there
   any reasonable candidate genes in the region.

   Peter Visscher and colleagues suggested using the bootstrap to get
   such a confidence interval. Lots of people were using it.
}
\end{frame}



\begin{frame}{LOD support interval}


\figh{Figs/hyper_lod.pdf}{0.85}

\vfill

\hfill {\footnotesize \lolit Data from Sugiyama et al.\ (2001) Genomics 71:70--77}

\note{
   The usual method of getting a confidence interval for QTL location
   was the LOD support interval: drop down from the maximum likelihood
   some fixed amount. In other words, look at the region where the LOD
   score is within some amount of its maximum.

   This ends up being the traditional sort of ``invert the
   hypothesis test'' approach for constructing a confidence interval,
   as the difference in LOD scores is a log$_{10}$ likelihood ratio.

   But various simulation studies showed that this doesn't behave as a
   real confidence interval. Coverage depends on a bunch of things,
   including the strength of the QTL effect, but also the type of
   cross and the relative locations of the markers to the QTL.
}

\end{frame}




\begin{frame}{Approximate Bayes interval}


\figh{Figs/hyper_bayes.pdf}{0.85}

\vfill

\hfill {\footnotesize \lolit Data from Sugiyama et al.\ (2001) Genomics 71:70--77}

\note{
  Another approach is an approximate Bayes interval. Basically take
  10$^{\text{LOD}}$ and treat it as if it were a real likelihood.
  Assume that the QTL location is uniform along the chromosome (as the
  prior distribution), and so re-scale the likelihood so that it
  integrates to 1, and you have the posterior. Drop down some amount
  from the maximum until you get a region that covers 95\% of the
  area, and take that as a 95\% Bayes credible interval.

  This hadn't been much studied, but it was one of the other
  approaches that I had considered using.
}

\end{frame}



\begin{frame}{Bootstrap CI}


\figh{Figs/hyper_boot.pdf}{0.85}

\vfill

\hfill {\footnotesize \lolit Data from Sugiyama et al.\ (2001) Genomics 71:70--77}

\note{
  Well, the thing is that the bootstrap in this context tended to
  behave rather strangely. Here are the bootstrap results for this
  dataset. They don't look quite right. I mean, they don't really
  reflect what you might perceive to be the uncertainty in QTL
  location.

  (Note that in the top graph, the dashed curve is the LOD curve with
  the original data. The three colored curves are results with
  different bootstrap samples.)

  The fact is, these LOD curves tend to achieve their maximum at the
  markers, and as a result, the bootstrap results have spikes at the
  marker positions, which makes the whole thing behave a bit wonky.

  I looked at these results and thought, ``We really should
  investigate this bootstrap thing. Does it really work here?''
}
\end{frame}











\begin{frame}{}

\figh{Figs/manichaikul2006.png}{0.9}

\note{
   We ended up writing this paper. The results are well summarized in
   the title. Nevertheless, Visscher's paper has $>$ 3$\times$ as
   many citations as mine. ;)
}
\end{frame}



\begin{frame}{Simulation study}


  \vspace*{-5mm}

  \bbi
\item {\hilit Backcross}, 200 individuals

\item One chromosome of length 100 cM

\item Markers at {\hilit 10 cM spacing}

\item {\hilit Single QTL} responsible for 10\% of phenotypic variance

\item Normally distributed residual variation

\item {\hilit Varied location of QTL}, at positions 0, 1, \dots, 100 cM

\item Analysis by standard interval mapping;
  calculations every 1 cM

\item 10,000 simulations for each QTL position

\item Bootstrap used 1000 replicates
\ei

\note{
   So what we did was a simulation study to see how well the bootstrap
   worked in this case.

   We considered a backcross (so there are two possible genotypes) and
   a single chromosome with equally-spaced markers.

   We simulated a single QTL and varied its location along the
   chromosome.

   For each QTL location, we did 10,000 simulation replicates. For
   each replicate, we did the QTL analysis and calculated three
   possible QTL intervals, including a bootstrap with 1000 replicates.
}
\end{frame}


\begin{frame}[c]{Distribution of estimated location}

\figh{Figs/mle1.pdf}{0.9}

\note{
   The first thing to look at is just the distribution of the
   estimated QTL locations. In these panels, the triangle is
   indicating the location of the QTL, and the histogram shows the
   distribution of its estimated location. Remember that the markers
   are placed every 10 cM.

   There's a clear tendency for the estimated location to be at a
   marker. When the QTL is right next to a marker, still the estimate
   ends up being mostly at the marker.
}
\end{frame}




\begin{frame}[c]{Distribution of estimated location}

\figh{Figs/mle2.pdf}{0.9}

\note{
  Here we move the QTL to the right a bit, at 6 - 14 cM. You again see
  the very strong tendency for the QTL to be at a marker.

  It's not that the estimated QTL position is {\hilit biased}, though
  that is sort of a problem here at the end of the chromosome. Rather,
  it's just an odd spike in the sampling distribution that is due to
  cusps in the likelihood function at the markers.
}
\end{frame}




\begin{frame}[c]{Distribution of estimated location}

\figh{Figs/mle4.pdf}{0.9}

\note{
  Here the QTL is near the center of the chromosome, but in the
  interval to the left. When the QTL is in an interval between
  markers, the estimate is somewhat more likely to be at one of the
  two flanking markers.
}
\end{frame}



\begin{frame}[c]{Coverage vs. true location}

\figh{Figs/coveraget.pdf}{0.9}

\note{
   Here now is the plot of the coverage of the three different types
   of intervals as a function of the location of the QTL.

   For each interval type, there is some variation in coverage
   depending on the true parameter value, with coverage being higher
   if the QTL is at a marker and lower if it is between markers.

   The bootstrap shows the greatest variation in coverage, with
   coverage being particularly high when the QTL is right at a marker,
   but being particularly low when it is just adjacent to a marker.

   To me, this variation in coverage is a killer for the bootstrap.
}
\end{frame}





\begin{frame}[c]{Coverage vs. estimated location}

\figh{Figs/coveragethat.pdf}{0.9}

\note{
   We had this idea to also look at coverage relative to the estimated
   location of the QTL, pooling results with different true QTL
   positions.

   The idea is that, for each simulation replicate, we have some QTL
   location and some estimated QTL location and an indicator of
   whether the interval covered the truth or not. In the previous
   graph, we binned replicates by the true QTL location and found the
   coverage rate in each bin.

   Here, though, we are binning the replicates by the {\hilit
   estimated} location. We are looking at the coverage in bins
   defined by the {\hilit estimated} location.

   This is rather unorthodox, but is super revealing, as you see that
   the coverage of the bootstrap intervals depends most critically on
   the {\hilit estimated} QTL location: if the QTL is estimated to be
   at a marker, the interval coverage is particularly low. The other
   two types of intervals show much more stable coverage here.
}
\end{frame}




\begin{frame}{Summary}

\note{
}
\end{frame}






\begin{frame}{Lessons}

\note{
}
\end{frame}


\end{document}
